apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: nvidia-device-plugin-daemonset
  name: nvidia-device-plugin-daemonset
  namespace: gpu-operator-resources
  annotations:
    openshift.io/scc: hostmount-anyuid
spec:
  selector:
    matchLabels:
      app: nvidia-device-plugin-daemonset
  template:
    metadata:
      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
      # reserves resources for critical add-on pods so that they can be rescheduled after
      # a failure.  This annotation works in tandem with the toleration below.
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ""
      labels:
        app: nvidia-device-plugin-daemonset
    spec:
      tolerations:
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      # This, along with the annotation above marks this pod as a critical add-on.
      - key: CriticalAddonsOnly
        operator: Exists
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      serviceAccount: nvidia-device-plugin
      initContainers:
      - name: toolkit-validation
        image: "FILLED BY THE OPERATOR"
        command: ['sh', '-c']
        args: ["until /tmp/vectorAdd; do echo waiting for nvidia drivers to be loaded; sleep 5; done"]
        securityContext:
          allowPrivilegeEscalation: false
      containers:
      - image: "FILLED BY THE OPERATOR"
        name: nvidia-device-plugin-ctr
        securityContext:
          privileged: true
        env:
          - name: NVIDIA_VISIBLE_DEVICES
            value: all
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
      nodeSelector:
        nvidia.com/gpu.present: "true"

